{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNNGpcpEN6oJX95v7OcT9DZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Price-Jack/bitcoin-digital-twin/blob/main/notebooks/bitcoin_digital_twin.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FbeH0Vd7qUSC"
      },
      "outputs": [],
      "source": [
        "# imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import (\n",
        "    mean_absolute_error, mean_squared_error, r2_score,\n",
        "    accuracy_score, precision_score, recall_score, f1_score,\n",
        "    confusion_matrix, ConfusionMatrixDisplay\n",
        ")\n",
        "from scipy.stats import ttest_ind\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import yfinance as yf\n",
        "\n",
        "plt.style.use(\"seaborn-v0_8\")\n",
        "\n",
        "# project settings\n",
        "TICKER = \"BTC-USD\"\n",
        "PERIOD = \"60d\"\n",
        "INTERVAL = \"5m\"\n",
        "LOOKBACK = 60\n",
        "HORIZON = 3\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def download_data(ticker=TICKER, period=PERIOD, interval=INTERVAL):\n",
        "    # pull stock data from yfinance\n",
        "    df = yf.download(\n",
        "        ticker,\n",
        "        period=period,\n",
        "        interval=interval,\n",
        "        auto_adjust=False,\n",
        "        progress=False\n",
        "    )\n",
        "\n",
        "    # check that all the price columns are there\n",
        "    expected = [\"Open\", \"High\", \"Low\", \"Close\", \"Adj Close\", \"Volume\"]\n",
        "    missing = [c for c in expected if c not in df.columns]\n",
        "    if missing:\n",
        "        raise ValueError(f\"Missing columns: {missing}\")\n",
        "\n",
        "   # drop rows with missing values\n",
        "    df = df.dropna()\n",
        "    return df\n",
        "\n",
        "df_raw = download_data()\n",
        "print(\"Raw data shape:\", df_raw.shape)\n",
        "df_raw.head()"
      ],
      "metadata": {
        "id": "33r_9iQCAM43"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate relative strength index\n",
        "def rsi(series, window=14):\n",
        "    delta = series.diff()\n",
        "    gain = delta.clip(lower=0)\n",
        "    loss = -delta.clip(upper=0)\n",
        "    avg_gain = gain.rolling(window=window).mean()\n",
        "    avg_loss = loss.rolling(window=window).mean()\n",
        "    rs = avg_gain / (avg_loss + 1e-8)\n",
        "    rsi = 100 - (100 / (1 + rs))\n",
        "    return rsi\n",
        "\n",
        "\n",
        "def build_features(df, horizon = 1):\n",
        "    # create a copy\n",
        "    data = df.copy()\n",
        "\n",
        "    # if yfinance does multiindex, flatten it\n",
        "    if isinstance(data.columns, pd.MultiIndex):\n",
        "        data.columns = data.columns.get_level_values(0)\n",
        "\n",
        "    # convert close to a series if it's somehow a dataframe\n",
        "    if isinstance(data[\"Close\"], pd.DataFrame):\n",
        "        data[\"Close\"] = data[\"Close\"].iloc[:, 0]\n",
        "\n",
        "    # basic 1-day return\n",
        "    data[\"return_1\"] = data[\"Close\"].pct_change()\n",
        "\n",
        "    # target variables for prediction\n",
        "    data[\"future_close\"] = data[\"Close\"].shift(-horizon)\n",
        "    data[\"future_return\"] = (data[\"future_close\"] - data[\"Close\"]) / data[\"Close\"]\n",
        "    data[\"future_up\"] = (data[\"future_return\"] > 0).astype(int)\n",
        "\n",
        "    # moving averages\n",
        "    data[\"ma5\"] = data[\"Close\"].rolling(window=5).mean()\n",
        "    data[\"ma10\"] = data[\"Close\"].rolling(window=10).mean()\n",
        "    data[\"ma20\"] = data[\"Close\"].rolling(window=20).mean()\n",
        "\n",
        "    # price volatility\n",
        "    data[\"vol10\"] = data[\"return_1\"].rolling(window=10).std()\n",
        "    data[\"vol20\"] = data[\"return_1\"].rolling(window=20).std()\n",
        "\n",
        "    # volume metrics\n",
        "    data[\"vol_mean_10\"] = data[\"Volume\"].rolling(window=10).mean()\n",
        "    data[\"vol_mean_20\"] = data[\"Volume\"].rolling(window=20).mean()\n",
        "\n",
        "    # momentum indicators\n",
        "    data[\"mom5\"] = data[\"return_1\"].rolling(window=5).mean()\n",
        "    data[\"mom10\"] = data[\"return_1\"].rolling(window=10).mean()\n",
        "\n",
        "    # relative strength index\n",
        "    data[\"rsi14\"] = rsi(data[\"Close\"], window=14)\n",
        "\n",
        "    # MACD and its components\n",
        "    ema_12 = data[\"Close\"].ewm(span=12, adjust=False).mean()\n",
        "    ema_26 = data[\"Close\"].ewm(span=26, adjust=False).mean()\n",
        "    data[\"MACD\"] = ema_12 - ema_26\n",
        "    data[\"MACD_signal\"] = data[\"MACD\"].ewm(span=9, adjust=False).mean()\n",
        "    data[\"MACD_hist\"] = data[\"MACD\"] - data[\"MACD_signal\"]\n",
        "\n",
        "    # bollinger band width\n",
        "    sma_20 = data[\"Close\"].rolling(window=20).mean()\n",
        "    std_20 = data[\"Close\"].rolling(window=20).std()\n",
        "    upper_bb = sma_20 + 2 * std_20\n",
        "    lower_bb = sma_20 - 2 * std_20\n",
        "    data[\"BB_width\"] = (upper_bb - lower_bb) / (sma_20 + 1e-8)\n",
        "\n",
        "    data = data.dropna()\n",
        "    feature_cols = [\n",
        "        \"Close\", \"return_1\",\n",
        "        \"ma5\", \"ma10\", \"ma20\",\n",
        "        \"vol10\", \"vol20\",\n",
        "        \"vol_mean_10\", \"vol_mean_20\",\n",
        "        \"mom5\", \"mom10\",\n",
        "        \"rsi14\",\n",
        "        \"MACD\", \"MACD_signal\", \"MACD_hist\",\n",
        "        \"BB_width\",\n",
        "    ]\n",
        "    x = data[feature_cols].values\n",
        "    y_reg = data[\"future_return\"].values\n",
        "    y_class = data[\"future_up\"].values\n",
        "\n",
        "    data.to_csv(\"btc_data.csv\")\n",
        "\n",
        "    return x, y_reg, y_class, data\n",
        "\n",
        "\n",
        "x, y_reg, y_class, df_feat = build_features(df_raw, horizon=HORIZON)\n",
        "\n",
        "# print(\"Feature matrix shape:\", x.shape)\n",
        "# print(\"Regression target shape:\", y_reg.shape)\n",
        "# print(\"Classification target shape:\", y_class.shape)\n",
        "\n",
        "df_feat.head()"
      ],
      "metadata": {
        "id": "ruCa4s6VDFOq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    from google.colab import files\n",
        "    files.download(\"btc_data.csv\")\n",
        "except Exception:\n",
        "    pass\n"
      ],
      "metadata": {
        "id": "XZMGcC94FDSZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 4))\n",
        "plt.plot(df_feat.index, df_feat[\"Close\"])\n",
        "plt.title(f\"{TICKER} Close Price (5-min groupings)\")\n",
        "plt.xlabel(\"Time\")\n",
        "plt.ylabel(\"Price (USD)\")\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "L9dX3h-NfcQs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n = len(df_feat)\n",
        "train_size = int(n * 0.7)\n",
        "\n",
        "# split to avoid lookahead\n",
        "x_train = x[:train_size]\n",
        "x_test = x[train_size:]\n",
        "y_return_train = y_reg[:train_size]\n",
        "y_return_test = y_reg[train_size:]\n",
        "y_direction_train = y_class[:train_size]\n",
        "y_direction_test = y_class[train_size:]\n",
        "\n",
        "# normalize features\n",
        "scaler = StandardScaler()\n",
        "x_train_scaled = scaler.fit_transform(x_train)\n",
        "x_test_scaled = scaler.transform(x_test)\n",
        "\n",
        "print(\"Train:\", x_train.shape, \"| Test:\", x_test.shape)\n",
        "\n",
        "# train a linear regression model\n",
        "return_model = LinearRegression()\n",
        "return_model.fit(x_train_scaled, y_return_train)\n",
        "y_return_pred = return_model.predict(x_test_scaled)\n",
        "\n",
        "mae = mean_absolute_error(y_return_test, y_return_pred)\n",
        "rmse = np.sqrt(mean_squared_error(y_return_test, y_return_pred))\n",
        "r2 = r2_score(y_return_test, y_return_pred)\n",
        "\n",
        "print(\"\\nRegression Performance:\")\n",
        "print(f\"MAE:  {mae:.6f}\")\n",
        "print(f\"RMSE: {rmse:.6f}\")\n",
        "print(f\"R²:   {r2:.4f}\")\n",
        "\n",
        "# train logistic regression for direction prediction\n",
        "direction_model = LogisticRegression(max_iter=2000)\n",
        "direction_model.fit(x_train_scaled, y_direction_train)\n",
        "y_direction_pred = direction_model.predict(x_test_scaled)\n",
        "\n",
        "accuracy = accuracy_score(y_direction_test, y_direction_pred)\n",
        "precision = precision_score(y_direction_test, y_direction_pred)\n",
        "recall = recall_score(y_direction_test, y_direction_pred)\n",
        "f1 = f1_score(y_direction_test, y_direction_pred)\n",
        "\n",
        "print(\"\\nLogistic Regression Classification Performance:\")\n",
        "print(f\"Accuracy:  {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall:    {recall:.4f}\")\n",
        "print(f\"F1 Score:  {f1:.4f}\")"
      ],
      "metadata": {
        "id": "rBoPEV5KDYBZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# reduce to 2D for plotting\n",
        "pca = PCA(n_components=2)\n",
        "x_reduced = pca.fit_transform(x_train_scaled)\n",
        "\n",
        "# see how much info is lost\n",
        "# print(\"Explained variance:\", pca.explained_variance_ratio_)\n",
        "# print(\"Total explained variance:\", pca.explained_variance_ratio_.sum())\n",
        "\n",
        "# plot the projection by whether price goes up or down\n",
        "plt.figure(figsize=(6, 5))\n",
        "plt.scatter(x_reduced[:, 0], x_reduced[:, 1], c=y_direction_train, cmap=\"coolwarm\", alpha=0.4)\n",
        "plt.title(\"PCA Projection\")\n",
        "plt.xlabel(\"PC1\")\n",
        "plt.ylabel(\"PC2\")\n",
        "plt.colorbar(label=\"direction\")\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Ih5QRfVqDgX_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# scale all data\n",
        "x_all_scaled = scaler.transform(x)\n",
        "\n",
        "def make_seqs(x_arr, y_arr, lookback=LOOKBACK):\n",
        "    seq_x, seq_y = [], []\n",
        "    for i in range(lookback, len(x_arr)):\n",
        "        seq_x.append(x_arr[i-lookback:i])\n",
        "        seq_y.append(y_arr[i])\n",
        "    return np.array(seq_x), np.array(seq_y)\n",
        "\n",
        "x_class_seq, y_class_seq = make_seqs(x_all_scaled, y_class)\n",
        "\n",
        "print(\"Sequenced features shape:\", x_class_seq.shape)\n",
        "print(\"Sequenced targets shape:\", y_class_seq.shape)\n",
        "\n",
        "n_seq = len(x_class_seq)\n",
        "train_size_seq = int(n_seq * 0.7)\n",
        "\n",
        "# train/test split for LSTM\n",
        "x_class_train = x_class_seq[:train_size_seq]\n",
        "x_class_test = x_class_seq[train_size_seq:]\n",
        "y_class_train_seq = y_class_seq[:train_size_seq]\n",
        "y_class_test_seq = y_class_seq[train_size_seq:]\n",
        "\n",
        "print(\"Train sequences:\", x_class_train.shape, \"& Test sequences:\", x_class_test.shape)\n"
      ],
      "metadata": {
        "id": "hqXWJRHhf-0D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils import class_weight\n",
        "\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "# compute class weights\n",
        "cls_weights = class_weight.compute_class_weight(\n",
        "    class_weight=\"balanced\",\n",
        "    classes=np.unique(y_class_train_seq),\n",
        "    y=y_class_train_seq\n",
        ")\n",
        "class_weights = {0: cls_weights[0], 1: cls_weights[1]}\n",
        "# print(\"Class weights used for LSTM:\", class_weights)\n",
        "\n",
        "# LSTM model\n",
        "model_class_lstm = Sequential([\n",
        "    LSTM(64, return_sequences=True, input_shape=(LOOKBACK, x_all_scaled.shape[1])),\n",
        "    Dropout(0.3),\n",
        "    LSTM(32),\n",
        "    Dropout(0.2),\n",
        "    Dense(32, activation=\"relu\"),\n",
        "    Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "\n",
        "model_class_lstm.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
        "    loss=\"binary_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "early_stop = EarlyStopping(\n",
        "    monitor=\"val_loss\",\n",
        "    patience=6,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "history = model_class_lstm.fit(\n",
        "    x_class_train,\n",
        "    y_class_train_seq,\n",
        "    validation_split=0.2,\n",
        "    epochs=50,\n",
        "    batch_size=64,\n",
        "    callbacks=[early_stop],\n",
        "    class_weight=class_weights,\n",
        "    verbose=1\n",
        ")\n"
      ],
      "metadata": {
        "id": "4G-Q81ZwgAry"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get predictions from the lstm (probabilities that price goes up)\n",
        "y_proba = model_class_lstm.predict(x_class_test).flatten()\n",
        "# make sure both arrays are the same length\n",
        "n_aligned = min(len(y_class_test_seq), len(y_proba))\n",
        "\n",
        "# trim to matching size\n",
        "y_true = y_class_test_seq[:n_aligned]\n",
        "y_pred_proba = y_proba[:n_aligned]\n",
        "\n",
        "print(\"Aligned shapes -> y_true:\", y_true.shape, \"| y_pred_proba:\", y_pred_proba.shape)\n"
      ],
      "metadata": {
        "id": "ghWEEMmigBvy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test different cutoff points to see what gives the best predictions\n",
        "thresholds = np.arange(0.40, 0.71, 0.01)\n",
        "\n",
        "best_threshold = 0.5\n",
        "best_f1 = 0.0\n",
        "\n",
        "# find threshold that maximizes f1\n",
        "for threshold in thresholds:\n",
        "    predictions = (y_pred_proba > threshold).astype(int)\n",
        "    f1 = f1_score(y_true, predictions)\n",
        "    if f1 > best_f1:\n",
        "        best_f1 = f1\n",
        "        best_threshold = threshold\n",
        "\n",
        "print(f\"Best threshold for F1: {best_threshold:.2f} (F1 = {best_f1:.4f})\")"
      ],
      "metadata": {
        "id": "paimBgTYgCyp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# apply the best threshold we found\n",
        "y_pred = (y_pred_proba > best_threshold).astype(int)\n",
        "\n",
        "# calculate how well the lstm performed\n",
        "accuracy = accuracy_score(y_true, y_pred)\n",
        "precision = precision_score(y_true, y_pred)\n",
        "recall = recall_score(y_true, y_pred)\n",
        "f1 = f1_score(y_true, y_pred)\n",
        "\n",
        "print(f\"LSTM Classification Performance:\")\n",
        "print(f\"Accuracy:  {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall:    {recall:.4f}\")\n",
        "print(f\"F1 Score:  {f1:.4f}\")"
      ],
      "metadata": {
        "id": "y72ZwbsfgD4R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create confusion matrix\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0, 1])\n",
        "\n",
        "# print confusion matrix\n",
        "plt.figure(figsize=(5, 5))\n",
        "disp.plot(cmap=\"Blues\", values_format=\"d\")\n",
        "plt.title(\"Confusion Matrix – LSTM (direction prediction)\")\n",
        "plt.xlabel(\"Predicted label\")\n",
        "plt.ylabel(\"True label\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kJwNpWZ5gEnq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# figure out which dates in our dataframe match the test predictions\n",
        "n_seq = len(x_class_seq)\n",
        "train_size_seq = int(n_seq * 0.7)\n",
        "test_start_idx = LOOKBACK + train_size_seq\n",
        "\n",
        "# grab the actual prices for those test dates\n",
        "test_len = len(y_pred_proba)\n",
        "prices = df_feat[\"Close\"].iloc[test_start_idx : test_start_idx + test_len]\n",
        "returns = prices.pct_change().fillna(0).values\n",
        "\n",
        "# set up two confidence levels for trading decisions\n",
        "weak_signal = best_threshold\n",
        "strong_signal = min(best_threshold + 0.10, 0.95)\n",
        "\n",
        "print(f\"Weak buy threshold:   {weak_signal:.2f}\")\n",
        "print(f\"Strong buy threshold: {strong_signal:.2f}\")\n",
        "\n",
        "# decide how much to invest based on model confidence\n",
        "positions = np.zeros_like(y_pred_proba, dtype=float)\n",
        "current_position = 0.0\n",
        "\n",
        "for i, confidence in enumerate(y_pred_proba):\n",
        "    if confidence >= strong_signal:\n",
        "        current_position = 1.0\n",
        "    elif confidence >= weak_signal:\n",
        "        current_position = 0.5\n",
        "    else:\n",
        "        current_position = 0.0\n",
        "    positions[i] = current_position\n",
        "\n",
        "# shift positions forward a day (cant trade on todays prediction until tomorrow)\n",
        "positions_shifted = np.roll(positions, 1)\n",
        "positions_shifted[0] = 0.0\n",
        "\n",
        "# calculate returns for both\n",
        "strategy_returns = positions_shifted * returns\n",
        "baseline_returns = returns\n",
        "\n",
        "# turn returns into cumulative growth\n",
        "strategy_equity = (1 + strategy_returns).cumprod()\n",
        "baseline_equity = (1 + baseline_returns).cumprod()\n",
        "\n",
        "# keep the dates attached to data\n",
        "strategy_equity = pd.Series(strategy_equity, index=prices.index, name=\"LSTM Strategy\")\n",
        "baseline_equity = pd.Series(baseline_equity, index=prices.index, name=\"Buy & Hold\")\n",
        "\n",
        "# compare the two approaches\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(strategy_equity, label=\"LSTM Strategy (confidence-weighted)\")\n",
        "plt.plot(baseline_equity, label=\"Buy & Hold\")\n",
        "plt.title(f\"Cumulative Returns: LSTM Strategy vs Buy & Hold (threshold={best_threshold:.2f})\")\n",
        "plt.ylabel(\"Growth of $1\")\n",
        "plt.xlabel(\"Time\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Rna55mPygFWB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compare the two strategies\n",
        "strategy_avg = strategy_returns.mean()\n",
        "strategy_vol = strategy_returns.std()\n",
        "baseline_avg = baseline_returns.mean()\n",
        "baseline_vol = baseline_returns.std()\n",
        "\n",
        "print(f\"Strategy avg:  {strategy_avg:.6f}, volatility: {strategy_vol:.6f}\")\n",
        "print(f\"Baseline avg:  {baseline_avg:.6f}, volatility: {baseline_vol:.6f}\")\n",
        "\n",
        "# check if the difference is statistically significant\n",
        "t_stat, p_value = ttest_ind(strategy_returns, baseline_returns, equal_var=False)\n",
        "\n",
        "print(f\"t-statistic: {t_stat:.4f}\")\n",
        "print(f\"p-value:     {p_value:.6f}\")"
      ],
      "metadata": {
        "id": "-GsXAE09gGh8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
